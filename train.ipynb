{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DiT Training Notebook\n",
    "\n",
    "This notebook trains the **Diffusion Transformer (DiT)** model on the MNIST dataset.\n",
    "\n",
    "## Training Objective\n",
    "\n",
    "The model learns to predict the noise that was added to an image during the forward diffusion process. This is the standard **DDPM** (Denoising Diffusion Probabilistic Models) approach.\n",
    "\n",
    "## Training Loop\n",
    "\n",
    "1. Sample a batch of clean images from the dataset\n",
    "2. Sample random timesteps for each image\n",
    "3. Add noise to images according to the forward diffusion process\n",
    "4. Use the DiT model to predict the noise\n",
    "5. Compute loss between predicted and actual noise\n",
    "6. Backpropagate and update model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from config import T\n",
    "from dataset import MNIST\n",
    "from diffusion import forward_add_noise\n",
    "from dit import DiT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration\n",
    "\n",
    "Set up device and training hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device selection: use GPU if available, otherwise CPU\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "print(f\"Device name: {torch.cuda.get_device_name(DEVICE)}\")\n",
    "print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "\n",
    "# Training hyperparameters\n",
    "EPOCH = 500  # Number of training epochs\n",
    "BATCH_SIZE = 1000  # Number of images per batch\n",
    "LEARNING_RATE = 1e-3  # Adam optimizer learning rate\n",
    "\n",
    "print(f\"Epochs: {EPOCH}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Learning rate: {LEARNING_RATE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset\n",
    "\n",
    "Load the MNIST dataset and create a DataLoader for batching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST training dataset\n",
    "# Each sample is a tuple of (image_tensor, label)\n",
    "# Image shape: (1, 28, 28), pixel range: [0, 1]\n",
    "dataset = MNIST()\n",
    "print(f\"Dataset size: {len(dataset)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader for batching and shuffling\n",
    "# - shuffle=True: Randomize order each epoch for better training\n",
    "# - num_workers=10: Use 10 parallel workers for data loading\n",
    "# - persistent_workers=True: Keep workers alive between epochs (faster)\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=10,\n",
    "    persistent_workers=True,\n",
    ")\n",
    "\n",
    "print(f\"Number of batches per epoch: {len(dataloader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model\n",
    "\n",
    "Initialize the DiT model with MNIST-specific parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the DiT model:\n",
    "# - img_size=28: MNIST images are 28x28 pixels\n",
    "# - patch_size=4: Split into 4x4 patches (7x7 = 49 patches total)\n",
    "# - channel=1: Grayscale images (1 channel)\n",
    "# - emb_size=128: 128-dimensional token embeddings\n",
    "# - label_num=10: 10 classes (digits 0-9)\n",
    "# - dit_num=6: 6 DiT transformer blocks\n",
    "# - head=8: 8 attention heads per block\n",
    "model = DiT(\n",
    "    img_size=28,\n",
    "    patch_size=4,\n",
    "    channel=1,\n",
    "    emb_size=128,\n",
    "    label_num=10,\n",
    "    dit_num=6,\n",
    "    head=8,\n",
    ").to(DEVICE)\n",
    "\n",
    "# Count parameters\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Model parameters: {num_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to load a previously saved model checkpoint\n",
    "# This allows resuming training from where we left off\n",
    "try:\n",
    "    model.load_state_dict(torch.load(\"model.pth\"))\n",
    "    print(\"Loaded existing model checkpoint\")\n",
    "except FileNotFoundError:\n",
    "    print(\"No checkpoint found, starting from scratch\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not load checkpoint: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Optimizer and Loss Function\n",
    "\n",
    "Set up the optimizer and loss function for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdamW optimizer with learning rate of 1e-3\n",
    "# AdamW is Adam with decoupled weight decay regularization\n",
    "# It's often preferred over Adam for training transformers\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# L1 Loss (Mean Absolute Error)\n",
    "# Measures average absolute difference between predicted and actual noise\n",
    "# Alternative: nn.MSELoss() (Mean Squared Error) is also commonly used\n",
    "loss_fn = nn.L1Loss()\n",
    "\n",
    "print(f\"Optimizer: AdamW\")\n",
    "print(f\"Loss function: L1Loss (Mean Absolute Error)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Loop\n",
    "\n",
    "The main training loop that iterates over epochs and batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model to training mode\n",
    "# This enables dropout, batch norm training behavior, etc.\n",
    "model.train()\n",
    "\n",
    "# Iteration counter for logging and checkpointing\n",
    "iter_count = 0\n",
    "\n",
    "print(f\"Starting training for {EPOCH} epochs...\")\n",
    "print(f\"Batch size: {BATCH_SIZE}, Batches per epoch: {len(dataloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(EPOCH):\n",
    "    for imgs, labels in dataloader:\n",
    "        # ==== Step 1: Prepare the data ====\n",
    "        \n",
    "        # Normalize pixel values from [0, 1] to [-1, 1]\n",
    "        # This matches the range of Gaussian noise (mean=0, std=1)\n",
    "        x = imgs * 2 - 1  # Shape: (batch, 1, 28, 28)\n",
    "        \n",
    "        # Sample random timesteps for each image in the batch\n",
    "        t = torch.randint(0, T, (imgs.size(0),))  # Shape: (batch,)\n",
    "        \n",
    "        # Class labels for conditional generation\n",
    "        y = labels  # Shape: (batch,)\n",
    "        \n",
    "        # ==== Step 2: Forward diffusion (add noise) ====\n",
    "        \n",
    "        # Add noise to images according to the forward diffusion process\n",
    "        x, noise = forward_add_noise(x, t)\n",
    "        \n",
    "        # ==== Step 3: Model prediction ====\n",
    "        \n",
    "        # The model predicts what noise was added to the image\n",
    "        pred_noise = model(x.to(DEVICE), t.to(DEVICE), y.to(DEVICE))\n",
    "        \n",
    "        # ==== Step 4: Compute loss ====\n",
    "        \n",
    "        # Compare predicted noise with actual noise using L1 loss\n",
    "        loss = loss_fn(pred_noise, noise.to(DEVICE))\n",
    "        \n",
    "        # ==== Step 5: Backpropagation and optimization ====\n",
    "        \n",
    "        optimizer.zero_grad()  # Clear gradients\n",
    "        loss.backward()  # Compute gradients\n",
    "        optimizer.step()  # Update weights\n",
    "        \n",
    "        # ==== Step 6: Logging and checkpointing ====\n",
    "        \n",
    "        if iter_count % 1000 == 0:\n",
    "            print(f\"Epoch: {epoch}, Iter: {iter_count}, Loss: {loss.item():.6f}\")\n",
    "            # Save checkpoint atomically\n",
    "            torch.save(model.state_dict(), \".model.pth\")\n",
    "            os.replace(\".model.pth\", \"model.pth\")\n",
    "        \n",
    "        iter_count += 1\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
