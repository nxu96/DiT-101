{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "bc2cf898",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "source": [
        "# Diffusion Process Implementation\n",
        "\n",
        "This notebook implements the **forward diffusion process** for DDPM (Denoising Diffusion Probabilistic Models).\n",
        "\n",
        "## Key Equations\n",
        "\n",
        "**Forward process:** $q(x_t | x_0) = \\mathcal{N}(x_t; \\sqrt{\\bar{\\alpha}_t} x_0, (1 - \\bar{\\alpha}_t) \\mathbf{I})$\n",
        "\n",
        "This allows us to sample $x_t$ directly from $x_0$ without iterating through all steps.\n",
        "\n",
        "## Notation\n",
        "\n",
        "| Symbol | Name | Description |\n",
        "|--------|------|-------------|\n",
        "| $\\beta_t$ | Beta | Variance schedule, controls noise added at each step |\n",
        "| $\\alpha_t$ | Alpha | $1 - \\beta_t$ |\n",
        "| $\\bar{\\alpha}_t$ | Alpha bar | $\\prod_{s=1}^{t} \\alpha_s$ (cumulative product) |\n",
        "\n",
        "**Reference:** \"Denoising Diffusion Probabilistic Models\" (Ho et al., 2020)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "be627f96",
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from config import T  # Total number of diffusion timesteps (e.g., 1000)\n",
        "from dataset import MNIST\n",
        "\n",
        "print(f\"Total diffusion timesteps T = {T}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10eac2fb",
      "metadata": {},
      "source": [
        "## 1. Diffusion Schedule Parameters\n",
        "\n",
        "These parameters define the noise schedule and are precomputed for efficiency."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f881ac77",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Beta schedule: linear increase from 0.0001 to 0.02 over T steps\n",
        "# β_t controls how much noise is added at each step\n",
        "# Small values at start (preserve structure) -> larger values at end (more noise)\n",
        "betas = torch.linspace(0.0001, 0.02, T)  # Shape: (T,)\n",
        "\n",
        "print(f\"betas shape: {betas.shape}\")\n",
        "print(f\"betas[0] = {betas[0]:.6f} (start)\")\n",
        "print(f\"betas[-1] = {betas[-1]:.6f} (end)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "52818b38",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Alpha: the \"keep\" ratio at each step (how much of the signal to retain)\n",
        "# α_t = 1 - β_t\n",
        "alphas = 1 - betas  # Shape: (T,)\n",
        "\n",
        "# Alpha cumulative product: product of all alphas from step 0 to t\n",
        "# α̅_t = α_1 * α_2 * ... * α_t\n",
        "# This tells us how much of the original signal remains at step t\n",
        "alphas_cumprod = torch.cumprod(alphas, dim=-1)  # Shape: (T,)\n",
        "\n",
        "# Alpha cumulative product for previous timestep (t-1)\n",
        "# Prepend 1.0 for t=0 case (no noise added yet, full signal)\n",
        "alphas_cumprod_prev = torch.cat(\n",
        "    (torch.tensor([1.0]), alphas_cumprod[:-1]), dim=-1\n",
        ")  # Shape: (T,)\n",
        "\n",
        "print(f\"alphas_cumprod[0] = {alphas_cumprod[0]:.4f} (almost all signal)\")\n",
        "print(f\"alphas_cumprod[-1] = {alphas_cumprod[-1]:.6f} (almost no signal)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "7ee01639",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Posterior variance: used in the reverse (denoising) process\n",
        "# This is the variance of q(x_{t-1} | x_t, x_0)\n",
        "# Formula: σ²_t = β_t * (1 - α̅_{t-1}) / (1 - α̅_t)\n",
        "variance = (1 - alphas) * (1 - alphas_cumprod_prev) / (1 - alphas_cumprod)  # Shape: (T,)\n",
        "\n",
        "print(f\"variance shape: {variance.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "16642cd9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize the diffusion schedule\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "axes[0].plot(betas.numpy())\n",
        "axes[0].set_title(\"Beta Schedule (β_t)\")\n",
        "axes[0].set_xlabel(\"Timestep t\")\n",
        "axes[0].set_ylabel(\"β_t\")\n",
        "\n",
        "axes[1].plot(alphas_cumprod.numpy())\n",
        "axes[1].set_title(\"Alpha Cumulative Product (α̅_t)\")\n",
        "axes[1].set_xlabel(\"Timestep t\")\n",
        "axes[1].set_ylabel(\"α̅_t\")\n",
        "\n",
        "axes[2].plot(variance.numpy())\n",
        "axes[2].set_title(\"Posterior Variance (σ²_t)\")\n",
        "axes[2].set_xlabel(\"Timestep t\")\n",
        "axes[2].set_ylabel(\"σ²_t\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90fd06ff",
      "metadata": {},
      "source": [
        "## 2. Forward Diffusion Process\n",
        "\n",
        "The key insight of DDPM is that we can sample $x_t$ directly from $x_0$ without iterating through all intermediate steps:\n",
        "\n",
        "$$x_t = \\sqrt{\\bar{\\alpha}_t} \\cdot x_0 + \\sqrt{1 - \\bar{\\alpha}_t} \\cdot \\epsilon$$\n",
        "\n",
        "where $\\epsilon \\sim \\mathcal{N}(0, \\mathbf{I})$ is standard Gaussian noise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "9c040ec5",
      "metadata": {},
      "outputs": [],
      "source": [
        "def forward_add_noise(x, t):\n",
        "    \"\"\"\n",
        "    Add noise to images according to the forward diffusion process.\n",
        "    \n",
        "    Args:\n",
        "        x: Clean images, shape (batch, channel, height, width), range [-1, 1]\n",
        "        t: Timesteps for each image, shape (batch,)\n",
        "    \n",
        "    Returns:\n",
        "        x_noisy: Noisy images, same shape as x\n",
        "        noise: The Gaussian noise that was added (training target)\n",
        "    \"\"\"\n",
        "    # Sample random Gaussian noise with same shape as input\n",
        "    noise = torch.randn_like(x)\n",
        "    \n",
        "    # Get α̅_t for each image's timestep and reshape for broadcasting\n",
        "    batch_alphas_cumprod = alphas_cumprod[t].view(x.size(0), 1, 1, 1)\n",
        "    \n",
        "    # Apply the forward diffusion formula:\n",
        "    # x_t = sqrt(α̅_t) * x_0 + sqrt(1 - α̅_t) * ε\n",
        "    x_noisy = (\n",
        "        torch.sqrt(batch_alphas_cumprod) * x\n",
        "        + torch.sqrt(1 - batch_alphas_cumprod) * noise\n",
        "    )\n",
        "    \n",
        "    return x_noisy, noise"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b35a68f",
      "metadata": {},
      "source": [
        "## 3. Visualization\n",
        "\n",
        "Let's load some MNIST images and see how the forward diffusion process adds noise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "7fcd30a9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load MNIST dataset\n",
        "dataset = MNIST()\n",
        "print(f\"Dataset size: {len(dataset)}\")\n",
        "\n",
        "# Stack 2 images into a batch: (2, 1, 28, 28)\n",
        "x = torch.stack((dataset[0][0], dataset[1][0]), dim=0)\n",
        "print(f\"Batch shape: {x.shape}\")\n",
        "print(f\"Image range is {x.min().item()} to {x.max().item()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "cf56d5ab",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display original images\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"Original Image 1\")\n",
        "plt.imshow(x[0].permute(1, 2, 0), cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"Original Image 2\")\n",
        "plt.imshow(x[1].permute(1, 2, 0), cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "38af6b9a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Normalize pixel values from [0, 1] to [-1, 1]\n",
        "# This matches the range of Gaussian noise (mean=0)\n",
        "x_normalized = x * 2 - 1\n",
        "\n",
        "# Sample random timesteps for each image\n",
        "t = torch.randint(0, T, size=(x.size(0),))\n",
        "print(f\"Timesteps: {t.tolist()}\")\n",
        "\n",
        "# Apply forward diffusion (add noise)\n",
        "x_noisy, noise = forward_add_noise(x_normalized, t)\n",
        "print(f\"Noisy image shape: {x_noisy.shape}\")\n",
        "print(f\"Noise shape: {noise.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "1a59c53b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display noisy images\n",
        "# Convert back from [-1, 1] to [0, 1] for visualization\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(f\"Noisy Image 1 (t={t[0].item()})\")\n",
        "plt.imshow(((x_noisy[0] + 1) / 2).permute(1, 2, 0), cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(f\"Noisy Image 2 (t={t[1].item()})\")\n",
        "plt.imshow(((x_noisy[1] + 1) / 2).permute(1, 2, 0), cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae9e4399",
      "metadata": {},
      "source": [
        "## 4. Noise Progression\n",
        "\n",
        "Let's visualize how a single image gets progressively noisier at different timesteps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "5f9f9f42",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Show noise progression for a single image at different timesteps\n",
        "single_img = x_normalized[0:1]  # Shape: (1, 1, 28, 28)\n",
        "\n",
        "# Select timesteps to visualize\n",
        "timesteps_to_show = [0, T//4, T//2, 3*T//4, T-1]\n",
        "\n",
        "plt.figure(figsize=(15, 3))\n",
        "for i, t_val in enumerate(timesteps_to_show):\n",
        "    t_tensor = torch.tensor([t_val])\n",
        "    noisy_img, _ = forward_add_noise(single_img, t_tensor)\n",
        "    \n",
        "    plt.subplot(1, len(timesteps_to_show), i + 1)\n",
        "    plt.title(f\"t = {t_val}\")\n",
        "    plt.imshow(((noisy_img[0] + 1) / 2).permute(1, 2, 0), cmap='gray')\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.suptitle(\"Forward Diffusion: Adding Noise Over Time\", fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
