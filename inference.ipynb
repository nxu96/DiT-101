{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DiT Inference Notebook\n",
    "\n",
    "This notebook performs **inference (image generation)** using a trained DiT model.\n",
    "\n",
    "## Reverse Diffusion Process\n",
    "\n",
    "The reverse process works by:\n",
    "1. Starting with pure random noise ($x_T$)\n",
    "2. Iteratively denoising from timestep $T-1$ down to $0$\n",
    "3. At each step, the model predicts the noise component\n",
    "4. We remove part of the predicted noise to get a cleaner image\n",
    "\n",
    "## DDPM Reverse Formula\n",
    "\n",
    "$$\\mu_\\theta(x_t, t) = \\frac{1}{\\sqrt{\\alpha_t}} \\left( x_t - \\frac{1-\\alpha_t}{\\sqrt{1-\\bar{\\alpha}_t}} \\epsilon_\\theta(x_t, t) \\right)$$\n",
    "\n",
    "$$x_{t-1} = \\mu_\\theta(x_t, t) + \\sigma_t \\cdot z, \\quad z \\sim \\mathcal{N}(0, \\mathbf{I})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from config import T\n",
    "from diffusion import alphas, alphas_cumprod, variance\n",
    "from dit import DiT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device selection: use GPU if available, otherwise CPU\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "print(f\"Total diffusion timesteps: {T}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define the Reverse Diffusion Function\n",
    "\n",
    "This function iteratively denoises an image from pure noise to a clean generated image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_denoise(model, x, y):\n",
    "    \"\"\"\n",
    "    Perform the reverse diffusion process to generate images from noise.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained DiT model\n",
    "        x: Initial noise tensor, shape (batch, channel, height, width)\n",
    "        y: Class labels for conditional generation, shape (batch,)\n",
    "    \n",
    "    Returns:\n",
    "        steps: List of tensors showing the denoising progression\n",
    "    \"\"\"\n",
    "    # Store intermediate results for visualization\n",
    "    steps = [x.clone()]\n",
    "    \n",
    "    # Move diffusion parameters to the correct device\n",
    "    print(\"Device of x before move:\", x.device)\n",
    "    alphas_device = alphas.to(DEVICE)\n",
    "    alphas_cumprod_device = alphas_cumprod.to(DEVICE)\n",
    "    variance_device = variance.to(DEVICE)\n",
    "    \n",
    "    # Move input tensors to device\n",
    "    x = x.to(DEVICE)\n",
    "    y = y.to(DEVICE)\n",
    "    print(\"Device of x after move:\", x.device)\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Disable gradient computation for inference\n",
    "    with torch.no_grad():\n",
    "        # Iterate backwards from T-1 to 0\n",
    "        for time in range(T - 1, -1, -1):\n",
    "            # Current timestep for the batch\n",
    "            t = torch.full((x.size(0),), time).to(DEVICE)\n",
    "            \n",
    "            # Step 1: Predict the noise at timestep t\n",
    "            noise = model(x, t, y)\n",
    "            \n",
    "            # Step 2: Compute the mean of x_{t-1}\n",
    "            shape = (x.size(0), 1, 1, 1)\n",
    "            alpha_t = alphas_device[t].view(*shape)\n",
    "            alpha_cumprod_t = alphas_cumprod_device[t].view(*shape)\n",
    "            variance_t = variance_device[t].view(*shape)\n",
    "            \n",
    "            # DDPM formula for posterior mean\n",
    "            # The key formula for DDPM reverse process.\n",
    "            mean = (1 / torch.sqrt(alpha_t)) * (\n",
    "                x - (1 - alpha_t) / torch.sqrt(1 - alpha_cumprod_t) * noise\n",
    "            )\n",
    "            # We are not like subtracting the noise from x_t,\n",
    "            # but calculating the mean and sample from the Gaussian distribution.\n",
    "            \n",
    "            # Step 3: Sample x_{t-1}\n",
    "            if time != 0:\n",
    "                # Add noise for t > 0\n",
    "                x = mean + torch.randn_like(x) * torch.sqrt(variance_t)\n",
    "            else:\n",
    "                # No noise for final step\n",
    "                x = mean\n",
    "            \n",
    "            # Clamp to prevent numerical instability\n",
    "            x = torch.clamp(x, -1.0, 1.0).detach()\n",
    "            steps.append(x.clone())\n",
    "    \n",
    "    return steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the DiT model with the same architecture used during training\n",
    "model = DiT(\n",
    "    img_size=28,\n",
    "    patch_size=4,\n",
    "    channel=1,\n",
    "    emb_size=64,\n",
    "    label_num=10,\n",
    "    dit_num=3,\n",
    "    head=4,\n",
    ").to(DEVICE)\n",
    "\n",
    "print(f\"Model architecture: DiT with {sum(p.numel() for p in model.parameters()):,} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained weights\n",
    "model.load_state_dict(torch.load(\"model.pth\"))\n",
    "print(\"Model weights loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generate Images\n",
    "\n",
    "Start with pure noise and denoise to generate images of each digit (0-9)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of images to generate (one for each digit 0-9)\n",
    "batch_size = 10\n",
    "\n",
    "# Start with pure random noise\n",
    "x = torch.randn(size=(batch_size, 1, 28, 28))\n",
    "\n",
    "# Class labels: generate one of each digit (0, 1, 2, ..., 9)\n",
    "y = torch.arange(start=0, end=10, dtype=torch.long)\n",
    "\n",
    "print(f\"Generating {batch_size} images...\")\n",
    "print(f\"Class labels: {y.tolist()}\")\n",
    "print(f\"Initial noise shape: {x.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the reverse diffusion process\n",
    "steps = backward_denoise(model, x, y)\n",
    "\n",
    "print(f\"Denoising complete!\")\n",
    "print(f\"Generated {len(steps)} intermediate steps (including initial noise)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize Final Results\n",
    "\n",
    "Show the generated images for each digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the final generated images\n",
    "plt.figure(figsize=(15, 2))\n",
    "\n",
    "for i in range(batch_size):\n",
    "    # Get final image (last step)\n",
    "    final_img = (steps[-1][i].to(\"cpu\") + 1) / 2  # Convert [-1,1] to [0,1]\n",
    "    final_img = final_img.permute(1, 2, 0)  # (C,H,W) -> (H,W,C)\n",
    "    \n",
    "    plt.subplot(1, batch_size, i + 1)\n",
    "    plt.imshow(final_img, cmap=\"gray\")\n",
    "    plt.title(f\"Digit {i}\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.suptitle(\"Generated Digits (0-9)\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Denoising Process\n",
    "\n",
    "Show how each image evolves from noise to the final digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of intermediate steps to show\n",
    "num_imgs = 20\n",
    "\n",
    "# Create a grid: rows = digits, columns = denoising steps\n",
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "for b in range(batch_size):\n",
    "    for i in range(num_imgs):\n",
    "        # Calculate which step to show (evenly spaced)\n",
    "        idx = int(T / num_imgs) * (i + 1)\n",
    "        \n",
    "        # Get image and convert to displayable format\n",
    "        img = (steps[idx][b].to(\"cpu\") + 1) / 2\n",
    "        img = img.permute(1, 2, 0)\n",
    "        \n",
    "        plt.subplot(batch_size, num_imgs, b * num_imgs + i + 1)\n",
    "        plt.imshow(img, cmap=\"gray\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "plt.suptitle(\"Denoising Process: Noise â†’ Generated Digit\\n(Each row is a different digit)\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Single Digit Deep Dive\n",
    "\n",
    "Let's look more closely at the denoising process for a single digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a digit to examine\n",
    "digit_to_show = 9\n",
    "\n",
    "# Show more steps for detailed view\n",
    "steps_to_show = [0, 50, 100, 200, 300, 400, 500, 600, 700, 800, 900, T]\n",
    "\n",
    "plt.figure(figsize=(15, 2))\n",
    "\n",
    "for i, step_idx in enumerate(steps_to_show):\n",
    "    # Clamp step_idx to valid range\n",
    "    step_idx = min(step_idx, len(steps) - 1)\n",
    "    \n",
    "    img = (steps[step_idx][digit_to_show].to(\"cpu\") + 1) / 2\n",
    "    img = img.permute(1, 2, 0)\n",
    "    \n",
    "    plt.subplot(1, len(steps_to_show), i + 1)\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    plt.title(f\"t={T - step_idx}\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.suptitle(f\"Denoising Process for Digit {digit_to_show}\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final generated images\n",
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "for b in range(batch_size):\n",
    "    for i in range(num_imgs):\n",
    "        idx = int(T / num_imgs) * (i + 1)\n",
    "        img = (steps[idx][b].to(\"cpu\") + 1) / 2\n",
    "        img = img.permute(1, 2, 0)\n",
    "        \n",
    "        plt.subplot(batch_size, num_imgs, b * num_imgs + i + 1)\n",
    "        plt.imshow(img, cmap=\"gray\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "plt.savefig(\"inference.png\", dpi=150, bbox_inches=\"tight\")\n",
    "print(\"Saved visualization to inference.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
